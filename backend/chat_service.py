import asyncio
import json
import sys
import os
from typing import AsyncGenerator, Dict, Any
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.messages import TextMessage
from autogen_core.model_context import BufferedChatCompletionContext
from llms import get_model_client

class ChatService:
    """èŠå¤©æœåŠ¡ç±»ï¼ŒåŸºäºAutoGenå®ç°"""
    
    def __init__(self):
        self.model_client = None
        self.agent = None
        self.conversation_history = []
        self._initialize_agent()
    
    def _initialize_agent(self):
        """åˆå§‹åŒ–AutoGenä»£ç†"""
        try:
            # è·å–æ¨¡å‹å®¢æˆ·ç«¯
            self.model_client = get_model_client()
            
            # åˆ›å»ºåŠ©æ‰‹ä»£ç†
            self.agent = AssistantAgent(
                name="ai_assistant",
                model_client=self.model_client,
                system_message="""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½AIåŠ©æ‰‹ï¼ŒåŸºäºAutoGenå’ŒDeepSeekæŠ€æœ¯ã€‚ä½ çš„ç‰¹ç‚¹ï¼š

1. å‹å¥½ã€ä¸“ä¸šã€æœ‰å¸®åŠ©
2. èƒ½å¤Ÿç†è§£ä¸­æ–‡å’Œè‹±æ–‡
3. å›ç­”å‡†ç¡®ã€è¯¦ç»†ä¸”æœ‰æ¡ç†
4. æ”¯æŒMarkdownæ ¼å¼è¾“å‡º
5. èƒ½å¤Ÿè¿›è¡Œå¤šè½®å¯¹è¯ï¼Œè®°ä½ä¸Šä¸‹æ–‡

è¯·ç”¨Markdownæ ¼å¼å›å¤ï¼Œè®©å›ç­”æ›´åŠ æ¸…æ™°æ˜“è¯»ã€‚å¯¹äºä»£ç ï¼Œè¯·ä½¿ç”¨ä»£ç å—æ ¼å¼ã€‚""",
                model_context=BufferedChatCompletionContext(buffer_size=10),  # ä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯
                model_client_stream=True,  # å¯ç”¨æµå¼è¾“å‡º
            )
            
            print("âœ… AutoGenä»£ç†åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–AutoGenä»£ç†å¤±è´¥: {e}")
            raise
    
    async def chat_stream(self, message: str) -> AsyncGenerator[Dict[str, Any], None]:
        """æµå¼èŠå¤©å“åº”"""
        try:
            print(f"ğŸ“ æ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯: {message}")
            
            # è®°å½•ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            self.conversation_history.append({
                "role": "user",
                "content": message,
                "timestamp": datetime.now()
            })
            
            # ä½¿ç”¨AutoGenä»£ç†è¿›è¡Œæµå¼å“åº”
            full_response = ""
            
            async for response_item in self.agent.run_stream(task=message):
                # å¤„ç†ä¸åŒç±»å‹çš„å“åº”
                if hasattr(response_item, 'content'):
                    if hasattr(response_item, 'type'):
                        # å¤„ç†æµå¼å“åº”å—
                        if response_item.type == 'ModelClientStreamingChunkEvent':
                            chunk_content = response_item.content
                            full_response += chunk_content
                            
                            yield {
                                "content": chunk_content,
                                "is_complete": False,
                                "timestamp": datetime.now().isoformat()
                            }
                        
                        # å¤„ç†å®Œæ•´çš„æ–‡æœ¬æ¶ˆæ¯
                        elif response_item.type == 'TextMessage':
                            if response_item.content and response_item.content != full_response:
                                # å¦‚æœæ˜¯å®Œæ•´æ¶ˆæ¯ä¸”ä¸æµå¼å†…å®¹ä¸åŒï¼Œä½¿ç”¨å®Œæ•´æ¶ˆæ¯
                                full_response = response_item.content
                    else:
                        # å¤„ç†TaskResultæˆ–å…¶ä»–ç±»å‹
                        if hasattr(response_item, 'messages') and response_item.messages:
                            last_message = response_item.messages[-1]
                            if hasattr(last_message, 'content'):
                                full_response = last_message.content
            
            # è®°å½•AIå›å¤åˆ°å†å²
            self.conversation_history.append({
                "role": "assistant", 
                "content": full_response,
                "timestamp": datetime.now()
            })
            
            # å‘é€å®Œæˆä¿¡å·
            yield {
                "content": "",
                "is_complete": True,
                "full_response": full_response,
                "timestamp": datetime.now().isoformat()
            }
            
            print(f"âœ… å›å¤å®Œæˆï¼Œé•¿åº¦: {len(full_response)}")
            
        except Exception as e:
            print(f"âŒ èŠå¤©æµå¼å“åº”é”™è¯¯: {e}")
            yield {
                "error": f"å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                "is_complete": True,
                "timestamp": datetime.now().isoformat()
            }
    
    async def chat(self, message: str) -> Dict[str, Any]:
        """éæµå¼èŠå¤©å“åº”"""
        try:
            print(f"ğŸ“ æ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯: {message}")
            
            # è®°å½•ç”¨æˆ·æ¶ˆæ¯
            self.conversation_history.append({
                "role": "user",
                "content": message,
                "timestamp": datetime.now()
            })
            
            # ä½¿ç”¨AutoGenä»£ç†è·å–å“åº”
            result = await self.agent.run(task=message)
            
            # æå–å›å¤å†…å®¹
            response_content = ""
            if result.messages:
                last_message = result.messages[-1]
                if hasattr(last_message, 'content'):
                    response_content = last_message.content
            
            # è®°å½•AIå›å¤
            self.conversation_history.append({
                "role": "assistant",
                "content": response_content,
                "timestamp": datetime.now()
            })
            
            print(f"âœ… å›å¤å®Œæˆ: {response_content[:100]}...")
            
            return {
                "content": response_content,
                "timestamp": datetime.now().isoformat(),
                "model_info": {
                    "model": "deepseek-chat",
                    "provider": "DeepSeek"
                }
            }
            
        except Exception as e:
            print(f"âŒ èŠå¤©å“åº”é”™è¯¯: {e}")
            raise
    
    def get_conversation_history(self) -> list:
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history.clear()
        print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…ç©º")
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æµ‹è¯•æ¨¡å‹è¿æ¥
            test_result = await self.agent.run(task="Hello")
            model_status = "healthy" if test_result else "unhealthy"
            
            return {
                "status": "healthy",
                "model_status": model_status,
                "autogen_version": "0.5.7",
                "conversation_count": len(self.conversation_history),
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def close(self):
        """å…³é—­æœåŠ¡ï¼Œæ¸…ç†èµ„æº"""
        try:
            if self.model_client:
                await self.model_client.close()
            print("ğŸ”’ èŠå¤©æœåŠ¡å·²å…³é—­")
        except Exception as e:
            print(f"âš ï¸ å…³é—­æœåŠ¡æ—¶å‡ºé”™: {e}")

# å…¨å±€èŠå¤©æœåŠ¡å®ä¾‹
chat_service = ChatService()
